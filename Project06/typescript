Script started on 2021-11-19 14:30:19-05:00 [TERM="xterm-256color" TTY="/dev/pts/0" COLUMNS="80" LINES="24"]
]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ ./calcPI2 1000 10make[Kcode .[2Pmakecat calcPI2.c pthreadReduction.h pthreadBarrierr.h [A]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ [29P./calcPI2 1000 10
[K[A]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ ./calcPI2 1000 10[7@0000000 10[1P810 10[Kcat calcPI2.c pthreadReduction.h pthreadBarrierr.h [A]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ make[K
[K[A]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ makecode .[2Pmake./calcPI2 1000 10[Kcat calcPI2.c pthreadBarrier.h pthreadReductionn.h 
/* calcPI2.c calculates PI using POSIX threads.
 * Since PI == 4 * arctan(1), and arctan(x) is the 
 *  integral from 0 to x of (1/(1+x*x),
 *  the for loop below approximates that integration.
 *
 * Joel Adams, Calvin College, Fall 2013.
 *
 * Usage: ./calcPI2 [numIntervals] [numThreads]
 * 
 * Modified By: John White
 * In order to: improve the programs performance by replacing the mutex zone with a new function that
 *              using a reduction pattern. The function resides in its own header file "pthreadReduction.h"
 *              and uses a barrier function created by professor Adams to syncronize the threads.
 * Date finished: 11/15/21
 * Completed for: CS374 @ Calvin University
 */

#include <stdio.h>                 // printf(), fprintf(), etc.
#include <stdlib.h>                // strtoul(), exit(), ...
#include <pthread.h>               // pthreads
#include <mpi.h>                   // MPI_Wtime()
#include "pthreadReduction.h"  	   // pthreadReductionSum()

// global variables (shared by all threads 
volatile long double pi = 0.0;       // our approximation of PI 
pthread_mutex_t      piLock;         // how we synchronize writes to 'pi' 
long double          intervals = 0;  // how finely we chop up the integration 
unsigned long        numThreads = 0; // how many threads we use 
long double *	     localArraySum;

/* compute PI using the parallel for loop pattern
 * Parameters: arg, a void* 
 * Preconditions: 
 *   - non-locals intervals and numThreads are defined.
 *   - arg contains the address of our thread's ID.
 * Postcondition: non-local pi contains our approximation of PI.
 */
void * computePI(void * arg)
{
    long double   x,
                  width,
                  localSum = 0;
    unsigned long i,
                  threadID = *((unsigned long *)arg);

    width = 1.0 / intervals;

    for(i = threadID ; i < intervals; i += numThreads) {
        x = (i + 0.5) * width;
        localSum += 4.0 / (1.0 + x*x);
    }

    localSum *= width; 
    
    // Place values into sum array in correct position using localSum varible
    localArraySum[threadID] = localSum;

    //ORIGINALLY IN PROGRAM
    /*
    pthread_mutex_lock(&piLock);
    pi += localSum;
    pthread_mutex_unlock(&piLock); 
    */

    // Call to pthreadReductionSum found in "pthreadReduction.h"
    // Function requires pi value, the locally allocated array, the thread ID, and the total number of threads
    pthreadReductionSum(&pi, localArraySum, threadID, numThreads);

    return NULL;
} 

/* process the command-line arguments
 * Parameters: argc, an int; and argv a char**.
 * Postcondition:
 *  - non-locals intervals and numThreads have been defined.
 *     according to the values the user specified when
 *     calcPI2 was invoked.
 */
void processCommandLine(int argc, char ** argv) {
   if ( argc == 3 ) {
      intervals = strtoul(argv[1], 0, 10); 
      numThreads = strtoul(argv[2], 0, 10); 
   } else if ( argc == 2 ) {
      intervals = strtoul(argv[1], 0, 10);
      numThreads = 1;
   } else if ( argc == 1 ) {
      intervals = 1;
      numThreads = 1;
   } else {
      fprintf(stderr, "\nUsage: calcPI2 [intervals] [numThreads]\n\n");
      exit(1);
   }
}
      

int main(int argc, char **argv) {
    pthread_t * threads;            // dynamic array of threads 
    unsigned long  * threadID;      // dynamic array of thread id #s 
    unsigned long i;                // loop control variable 
    double startTime = 0,           // timing variables
           stopTime = 0;

    processCommandLine(argc, argv);

    MPI_Init(&argc, &argv);

    threads = malloc(numThreads*sizeof(pthread_t));
    threadID = malloc(numThreads*sizeof(unsigned long));

    // array needs memory to be allocated for it (used malloc for dynamic allocation)
    // use of malloc noted from https://hpc-tutorials.llnl.gov/posix/samples/mpithreads_mpi.c
    localArraySum = (long double *)malloc( numThreads * sizeof(long double));

    pthread_mutex_init(&piLock, NULL);

    startTime = MPI_Wtime();

    for (i = 0; i < numThreads; i++) {   // fork threads
        threadID[i] = i;
        pthread_create(&threads[i], NULL, computePI, threadID+i);
    }

    for (i = 0; i < numThreads; i++) {   // join them
        pthread_join(threads[i], NULL);
    }
    stopTime = MPI_Wtime();

    printf("Estimation of pi is %32.30Lf in %lf secs\n", pi, stopTime - startTime);
    printf("(actual pi value is 3.141592653589793238462643383279...)\n");
   
    pthread_mutex_destroy(&piLock);
    free(threads);
    free(threadID);
    return 0;
}

/* pthreadBarrier.h implements the Barrier pattern using pthreads.
 *
 * Joel Adams, Calvin College, Fall 2013.
 */

#include <pthread.h>    // various pthread functions

// Shared Variables used to implement the barrier
   pthread_mutex_t barrierMutex = PTHREAD_MUTEX_INITIALIZER;
   pthread_cond_t allThreadsPresent = PTHREAD_COND_INITIALIZER;
   double barrierThreadCount = 0;

/* the Barrier pattern for pthreads
 * params: numThreads, the number of threads being synchronized
 * postcondition: all of those threads have reached this call
 *                 and are now ready to proceed.
 */
void pthreadBarrier(unsigned long numThreads) {
   pthread_mutex_lock( &barrierMutex );
   barrierThreadCount++;
   if (barrierThreadCount == numThreads) {
      barrierThreadCount = 0;
      pthread_cond_broadcast( &allThreadsPresent );
   } else {
      while ( pthread_cond_wait( &allThreadsPresent, &barrierMutex) != 0 );
   }
   pthread_mutex_unlock( &barrierMutex );
}

void barrierCleanup() {
   pthread_mutex_destroy(&barrierMutex);
   pthread_cond_destroy(&allThreadsPresent);
}

/* pthreadReduction.h implements the Barrier pattern using pthreads.
 *
 * John white, Calvin Uni, Fall 2021.
 * 
 * Function of file is to seperate the pthreadReductionSum function in order to call it in CalcPI2.c
 *             The function utilizes pthreadBarrier in order to synchronize the threads. Function requires pi value, 
 *             the locally allocated array, the thread ID, and the total number of threads. Filters through retults 
 *             using the tree method and is only performed if there are values to add.
 */

#include <stdlib.h>
#include <stdio.h>
#include "pthreadBarrier.h"     // pthreadBarrier()


void pthreadReductionSum(volatile long double * totalSum, long double * localArraySum, unsigned long threadID, unsigned long numThreads) {

    // syncronize all the threads allowing for the sum to not have any race conditions
    pthreadBarrier(numThreads);

    // array offset = offset value for the index 
    for (unsigned long arrayOffset = ((unsigned long) numThreads / 2); arrayOffset > 0; arrayOffset>>=1){
        // not all threads are needed
        if (threadID < arrayOffset) {
            //sum up all the values into the 0 thread (reduce)
            localArraySum[threadID] += localArraySum[(int)(threadID + arrayOffset)];
        }
        // re-sync threads
        pthreadBarrier(numThreads);
    }

    // de allocate barrier data
    barrierCleanup();
    // the first item in the array is the sum of all the other items, store first item
    if (threadID == 0){ *totalSum = localArraySum[0]; }
}]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ [Kmka  ake
make: 'calcPI2' is up to date.
]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ ./calcPI2 1000000000 4
Estimation of pi is 3.141592653589793591745876755184 in 1.470426 secs
(actual pi value is 3.141592653589793238462643383279...)
]0;jmw75@maroon09: ~/cs374/Project06[01;32mjmw75@maroon09[00m:[01;34m~/cs374/Project06[00m$ exit

Script done on 2021-11-19 14:31:32-05:00 [COMMAND_EXIT_CODE="0"]
